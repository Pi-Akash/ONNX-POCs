{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "187d07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d5270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the location of dataset stored in my local\n",
    "path = \"D:/Datasets/ShapesCNN/shapes/shapes/\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e92f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "train_path = os.path.join(path, 'training_set')\n",
    "test_path = os.path.join(path, 'test_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013beeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomVerticalFlip(p = 0.5),\n",
    "    transforms.RandomRotation((30, 60)),\n",
    "])\n",
    "trainset = datasets.ImageFolder(train_path, transform = transform)\n",
    "testset = datasets.ImageFolder(test_path, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98fd613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 4, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 4, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67c6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8f2435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 28, 28]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcbf801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross entropy loss \n",
    "#loss = nn.CrossEntropyLoss()\n",
    "#inps = torch.randn(3,5, requires_grad = True)\n",
    "#target = torch.empty(3, dtype = torch.long).random_(5)\n",
    "#output = loss(inps, target)\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1bf463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes = 3):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 4, kernel_size = 3),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(4, 4, kernel_size = 3),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Linear(100, 50),\n",
    "            nn.Linear(50, 25),\n",
    "            nn.Linear(25, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3f00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_input = torch.zeros(4, 3, 28, 28)\n",
    "# model = Net(in_channels = 3).to(device)\n",
    "# model(temp_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e39f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(in_channels = 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c620eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36e522f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbd6c978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19, loss : 0.492\n",
      "Epoch : 39, loss : 1.369\n",
      "Epoch : 59, loss : 0.455\n",
      "Epoch : 79, loss : 0.511\n",
      "Epoch : 99, loss : 1.918\n",
      "Epoch : 119, loss : 1.53\n",
      "Epoch : 139, loss : 0.195\n",
      "Epoch : 159, loss : 0.628\n",
      "Epoch : 179, loss : 0.246\n",
      "Epoch : 199, loss : 0.875\n",
      "Epoch : 219, loss : 0.082\n",
      "Epoch : 239, loss : 0.51\n",
      "Epoch : 259, loss : 1.193\n",
      "Epoch : 279, loss : 0.283\n",
      "Epoch : 299, loss : 0.603\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, target)\n",
    "        train_loss.append(loss)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(\"Epoch : {}, loss : {}\".format(epoch, round(loss.item(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7968c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        print(\"Accuracy : \", float(num_correct) / float(num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22d8f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8428571428571429\n",
      "Accuracy :  0.7444444444444445\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(trainloader, model)\n",
    "check_accuracy(testloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03703677",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('/models'):\n",
    "    os.mkdir(\"models\")\n",
    "else:\n",
    "    print(\"Folder exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dd68d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/shape_25052021.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f695ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exporting to onnx model\n",
    "trained_model = Net(in_channels = 3)\n",
    "trained_model.load_state_dict(torch.load('models/shape_25052021.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47f7929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 RGB 28 x 28 image is dummy input to model\n",
    "dummy_input = torch.randn(1, 3, 28, 28)\n",
    "torch.onnx.export(trained_model, dummy_input, \"models/shape_25052021.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf4aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
